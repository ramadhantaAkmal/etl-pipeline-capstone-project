{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline - Data Extraction\n",
    "\n",
    "This notebook is part of the ETL (Extract, Transform, Load) pipeline for the Capstone 1 project at Purwadhika School. The focus here is on the **extraction phase**, where multiple CSV files from a specified directory are read, filtered, and converted into pandas DataFrames for further processing.\n",
    "\n",
    "## Objectives\n",
    "- Read CSV files from the directory specified in `EXTRACT_PATH`.\n",
    "- Filter files based on specific key columns (`Country Name`, `Country Code`, `Indicator Name`, `Indicator Code`).\n",
    "- Detect file encodings using `charset_normalizer` to ensure proper reading of CSV files.\n",
    "- Extract relevant CSV files into pandas DataFrames.\n",
    "\n",
    "## Libraries Used\n",
    "- **glob**: To find all CSV files in the specified directory.\n",
    "- **pandas**: To handle data manipulation and create DataFrames.\n",
    "- **charset_normalizer**: To detect the encoding of CSV files for accurate reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57bd4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import charset_normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Utility Imports\n",
    "\n",
    "The following cell imports the `EXTRACT_PATH` from the `settings.py` file in the `config` directory, which specifies the directory containing the input CSV files. The `extract_csv` function from the `extract` module is also imported to handle CSV file extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169911f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.settings import EXTRACT_PATH\n",
    "from extract.extract import extract_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering CSV Files\n",
    "\n",
    "This section identifies CSV files in the `EXTRACT_PATH` directory that contain specific key columns (`Country Name`, `Country Code`, `Indicator Name`, `Indicator Code`). It reads the first 10 lines of each file to check for these columns in the header (assumed to be on line 5). Files that match the criteria are stored in the `filtered_files` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c51b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'{EXTRACT_PATH}/*.csv')\n",
    "\n",
    "key_columns = [\"Country Name\", \"Country Code\", \"Indicator Name\", \"Indicator Code\"]\n",
    "filtered_files = []\n",
    "\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        for i in range(10):\n",
    "            line = f.readline()\n",
    "            if i == 4:  # Check line 5 for key columns\n",
    "                if any(e in line for e in key_columns):\n",
    "                    filtered_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data to DataFrames\n",
    "\n",
    "The `extract_data_to_df` function extracts data from CSV files in the specified path into pandas DataFrames. It:\n",
    "- Uses `glob` to find all CSV files.\n",
    "- Detects the encoding of each file using `charset_normalizer` to ensure proper reading.\n",
    "- Checks for the presence of key columns in the specified line (default is line 0, but can be adjusted with `skip_line`).\n",
    "- Uses the `extract_csv` function to read valid CSV files into DataFrames.\n",
    "- Returns a list of DataFrames for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_to_df(path: str, key_columns: list[str], skip_line: int = 0) -> list[pd.DataFrame]:  \n",
    "    files = glob.glob(f'{path}/*.csv')\n",
    "\n",
    "    df_list: list[pd.DataFrame] = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as fil:\n",
    "            result = charset_normalizer.detect(fil.read())\n",
    "            print(file)\n",
    "            print(result)\n",
    "            \n",
    "        with open(file) as f:\n",
    "            for i in range(10):\n",
    "                line = f.readline()\n",
    "                if i == skip_line:\n",
    "                    if any(e in line for e in key_columns):\n",
    "                        df = extract_csv(file, skip_line)\n",
    "                        df_list.append(df)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Extraction\n",
    "\n",
    "This cell executes the `extract_data_to_df` function to process CSV files in the `EXTRACT_PATH` directory. It checks for the key columns on line 5 (index 4) and prints the detected encoding for each file. The resulting DataFrames are stored in the `df` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\\electricity_access_percent.csv\n",
      "{'encoding': 'UTF-8-SIG', 'language': 'English', 'confidence': 1.0}\n",
      "./data\\projects_data.csv\n",
      "{'encoding': 'utf-8', 'language': 'English', 'confidence': 0.917}\n",
      "./data\\mystery.csv\n",
      "{'encoding': 'UTF-16', 'language': 'Vietnamese', 'confidence': 1.0}\n",
      "./data\\population_data.csv\n",
      "{'encoding': 'UTF-8-SIG', 'language': 'English', 'confidence': 1.0}\n",
      "./data\\rural_population_percent.csv\n",
      "{'encoding': 'UTF-8-SIG', 'language': 'English', 'confidence': 1.0}\n",
      "./data\\gdp_data.csv\n",
      "{'encoding': 'UTF-8-SIG', 'language': 'Finnish', 'confidence': 1.0}\n"
     ]
    }
   ],
   "source": [
    "df = extract_data_to_df(EXTRACT_PATH, key_columns, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying File Encodings\n",
    "\n",
    "This section verifies the encoding of the filtered CSV files using `charset_normalizer`. It reads each file in binary mode, detects the encoding, and prints the results. This step ensures that files are read correctly in the ETL pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d0cc86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'UTF-8-SIG', 'language': 'English', 'confidence': 1.0}\n",
      "{'encoding': 'UTF-8-SIG', 'language': 'English', 'confidence': 1.0}\n",
      "{'encoding': 'UTF-8-SIG', 'language': 'English', 'confidence': 1.0}\n",
      "{'encoding': 'UTF-8-SIG', 'language': 'Finnish', 'confidence': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for file in filtered_files:\n",
    "    with open(file, 'rb') as fil:\n",
    "        result = charset_normalizer.detect(fil.read())\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e91802",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- The `extract_csv` function (imported from `extract.extract`) is to handle the actual CSV reading logic with proper encoding and skip rows.\n",
    "- The `skip_line` parameter in `extract_data_to_df` allows flexibility in handling CSV files with headers in different rows.\n",
    "- Ensure the `EXTRACT_PATH` in `settings.py` points to the correct directory containing the CSV files.\n",
    "- The pipeline filters out files like `mystery.csv` if they do not contain the key columns or have incompatible encodings (e.g., UTF-16)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
